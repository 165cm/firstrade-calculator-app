"""
Nemotron-Instagram çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

å…¨è‡ªå‹•ã§ãƒšãƒ«ã‚½ãƒŠé¸å®šã‹ã‚‰Instagramåˆ†æã€çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¾ã§å®Ÿè¡Œ
"""

import sys
import os
from pathlib import Path
from typing import Dict, List, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# Skillã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
skill_core = Path(__file__).parent
sys.path.insert(0, str(skill_core))

from lib.nemotron_persona_selector import NemotronPersonaSelector
from lib.instagram_keyword_generator import InstagramKeywordGenerator
from lib.persona_integrator import PersonaIntegrator
from apify_client import ApifyInstagramClient


class NemotronInstagramPipeline:
    """
    Nemotron-Instagram çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    1. Nemotron ãƒšãƒ«ã‚½ãƒŠé¸å®š
    2. Instagram ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
    3. Apify API ã§ãƒ‡ãƒ¼ã‚¿å–å¾—
    4. ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ»ä¿¡é ¼æ€§è©•ä¾¡
    5. Markdown ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    """

    def __init__(
        self,
        apify_token: Optional[str] = None,
        keyword_mapping_file: Optional[str] = None
    ):
        """
        åˆæœŸåŒ–

        Args:
            apify_token: Apify APIãƒˆãƒ¼ã‚¯ãƒ³ (çœç•¥æ™‚ã¯ç’°å¢ƒå¤‰æ•°)
            keyword_mapping_file: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        """
        print("=" * 70)
        print("ğŸš€ Nemotron-Instagram ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...")
        print("=" * 70)

        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
        self.nemotron_selector = NemotronPersonaSelector()

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆå™¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ä½¿ç”¨)
        if keyword_mapping_file is None:
            keyword_mapping_file = project_root / "config" / "keyword_mapping.json"
        self.keyword_generator = InstagramKeywordGenerator(str(keyword_mapping_file))

        self.apify_client = ApifyInstagramClient(apify_token)
        self.integrator = PersonaIntegrator()

        print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†\n")

    def run(
        self,
        target_description: str,
        max_personas: int = 3,
        max_posts_per_keyword: int = 20,
        max_profiles: int = 10,
        min_trust_score: int = 60
    ) -> Dict:
        """
        å…¨è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

        Args:
            target_description: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨˜è¿° (ä¾‹: "30ä»£ã®ITã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢")
            max_personas: æœ€å¤§é¸å®šãƒšãƒ«ã‚½ãƒŠæ•°
            max_posts_per_keyword: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§æŠ•ç¨¿æ•°
            max_profiles: æœ€å¤§ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ•°
            min_trust_score: æœ€ä½ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ (ã“ã®å€¤ä»¥ä¸Šã®ãƒšãƒ«ã‚½ãƒŠã®ã¿æ¡ç”¨)

        Returns:
            çµ±åˆçµæœ (ãƒšãƒ«ã‚½ãƒŠãƒªã‚¹ãƒˆã€Markdownãƒ¬ãƒãƒ¼ãƒˆç­‰)
        """
        print("=" * 70)
        print(f"ğŸ“Š ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: '{target_description}'")
        print("=" * 70)

        # ã‚¹ãƒ†ãƒƒãƒ—1: Nemotron ãƒšãƒ«ã‚½ãƒŠé¸å®š
        print("\nã€ã‚¹ãƒ†ãƒƒãƒ—1/5ã€‘Nemotron ãƒšãƒ«ã‚½ãƒŠé¸å®š")
        personas = self.nemotron_selector.select_personas(
            target_description,
            max_results=max_personas
        )

        if not personas:
            return {
                "success": False,
                "error": "æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒšãƒ«ã‚½ãƒŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                "personas": [],
                "markdown_report": "# ã‚¨ãƒ©ãƒ¼\n\næ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒšãƒ«ã‚½ãƒŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            }

        print(f"\né¸å®šãƒšãƒ«ã‚½ãƒŠ: {len(personas)}ä»¶")
        for i, p in enumerate(personas, 1):
            print(f"  {i}. {p.get('occupation')} ({p.get('age')}æ­³, {p.get('prefecture')})")

        # ã‚¹ãƒ†ãƒƒãƒ—2: Instagram ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
        print("\nã€ã‚¹ãƒ†ãƒƒãƒ—2/5ã€‘Instagram ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ")

        # çµ±åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ (è¤‡æ•°ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰ç”Ÿæˆ)
        all_keywords = []
        for persona in personas[:2]:  # ä¸Šä½2ãƒšãƒ«ã‚½ãƒŠ
            keywords = self.keyword_generator.generate_keywords(persona, max_keywords=10)
            all_keywords.extend(keywords)

        # é‡è¤‡å‰Šé™¤
        unique_keywords = list(dict.fromkeys(all_keywords))[:15]  # æœ€å¤§15ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        print(f"ç”Ÿæˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {unique_keywords}")

        # ã‚¹ãƒ†ãƒƒãƒ—3: Instagram ãƒ‡ãƒ¼ã‚¿å–å¾—
        print("\nã€ã‚¹ãƒ†ãƒƒãƒ—3/5ã€‘Instagram ãƒ‡ãƒ¼ã‚¿å–å¾— (Apify API)")

        instagram_data = None
        try:
            instagram_data = self.apify_client.search_combined(
                keywords=unique_keywords,
                max_posts_per_keyword=max_posts_per_keyword,
                max_profiles=max_profiles,
                timeout=180
            )
        except Exception as e:
            print(f"âš ï¸ Instagram ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
            print("  â†’ Nemotron ã®ã¿ã§çµ±åˆã‚’ç¶šè¡Œã—ã¾ã™ (ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ä½ä¸‹)")

        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        print("\nã€ã‚¹ãƒ†ãƒƒãƒ—4/5ã€‘ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ»ä¿¡é ¼æ€§è©•ä¾¡")

        integrated_personas = []
        for persona in personas:
            integrated = self.integrator.integrate(persona, instagram_data)
            trust_score = integrated.get("ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", 0)

            print(f"  ãƒšãƒ«ã‚½ãƒŠ: {persona.get('occupation')} â†’ ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {trust_score}/100")

            # æœ€ä½ã‚¹ã‚³ã‚¢ä»¥ä¸Šã®ã¿æ¡ç”¨
            if trust_score >= min_trust_score:
                integrated_personas.append(integrated)
            else:
                print(f"    âš ï¸ ã‚¹ã‚³ã‚¢ä¸è¶³ (æœ€ä½{min_trust_score}ç‚¹å¿…è¦)")

        if not integrated_personas:
            print(f"\nâš ï¸ ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢{min_trust_score}ç‚¹ä»¥ä¸Šã®ãƒšãƒ«ã‚½ãƒŠãŒã‚ã‚Šã¾ã›ã‚“")
            print("  â†’ æœ€ä½ã‚¹ã‚³ã‚¢ã‚’ä¸‹ã’ã‚‹ã‹ã€Instagram ãƒ‡ãƒ¼ã‚¿ã‚’æ”¹å–„ã—ã¦ãã ã•ã„")

        # ã‚¹ãƒ†ãƒƒãƒ—5: Markdown ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("\nã€ã‚¹ãƒ†ãƒƒãƒ—5/5ã€‘Markdown ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")

        markdown_reports = []
        for i, integrated in enumerate(integrated_personas, 1):
            report = self.integrator.format_output(integrated)
            markdown_reports.append(f"## ãƒšãƒ«ã‚½ãƒŠ {i}\n\n{report}\n\n---\n")

        # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ
        full_report = self._generate_summary_report(
            target_description,
            personas,
            instagram_data,
            integrated_personas
        )
        full_report += "\n\n" + "\n\n".join(markdown_reports)

        print("\n" + "=" * 70)
        print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†")
        print("=" * 70)

        return {
            "success": True,
            "target_description": target_description,
            "nemotron_personas": personas,
            "instagram_data": instagram_data,
            "integrated_personas": integrated_personas,
            "markdown_report": full_report,
            "total_personas": len(integrated_personas),
            "avg_trust_score": sum(p.get("ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", 0) for p in integrated_personas) / len(integrated_personas) if integrated_personas else 0
        }

    def _generate_summary_report(
        self,
        target: str,
        nemotron_personas: List[Dict],
        instagram_data: Optional[Dict],
        integrated_personas: List[Dict]
    ) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = []
        report.append("# Nemotron-Instagram ãƒšãƒ«ã‚½ãƒŠåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("")
        report.append(f"**ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ**: {target}")
        report.append(f"**åˆ†ææ—¥æ™‚**: {self._get_timestamp()}")
        report.append("")

        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±
        report.append("## ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")
        report.append(f"- **Nemotron ãƒšãƒ«ã‚½ãƒŠ**: {len(nemotron_personas)}ä»¶é¸å®š")

        if instagram_data:
            report.append(f"- **Instagram æŠ•ç¨¿**: {instagram_data.get('total_posts', 0)}ä»¶å–å¾—")
            report.append(f"- **Instagram ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«**: {instagram_data.get('total_profiles', 0)}ä»¶å–å¾—")
            report.append(f"- **æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(instagram_data.get('keywords', [])[:5])}")
        else:
            report.append("- **Instagram ãƒ‡ãƒ¼ã‚¿**: å–å¾—å¤±æ•—")

        report.append("")

        # çµ±åˆçµæœã‚µãƒãƒªãƒ¼
        report.append("## çµ±åˆçµæœã‚µãƒãƒªãƒ¼")
        report.append(f"- **çµ±åˆãƒšãƒ«ã‚½ãƒŠæ•°**: {len(integrated_personas)}ä»¶")

        if integrated_personas:
            avg_score = sum(p.get("ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", 0) for p in integrated_personas) / len(integrated_personas)
            report.append(f"- **å¹³å‡ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢**: {avg_score:.1f}/100")

            # ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
            high_trust = sum(1 for p in integrated_personas if p.get("ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", 0) >= 80)
            medium_trust = sum(1 for p in integrated_personas if 60 <= p.get("ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", 0) < 80)
            low_trust = sum(1 for p in integrated_personas if p.get("ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", 0) < 60)

            report.append(f"  - é«˜ä¿¡é ¼æ€§ (80-100ç‚¹): {high_trust}ä»¶")
            report.append(f"  - ä¸­ä¿¡é ¼æ€§ (60-79ç‚¹): {medium_trust}ä»¶")
            report.append(f"  - ä½ä¿¡é ¼æ€§ (0-59ç‚¹): {low_trust}ä»¶")

        report.append("")
        report.append("---")
        report.append("")

        return "\n".join(report)

    def _get_timestamp(self) -> str:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Nemotron-Instagram ãƒšãƒ«ã‚½ãƒŠåˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"
    )
    parser.add_argument(
        "target",
        type=str,
        help="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨˜è¿° (ä¾‹: '30ä»£ã®ITã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢')"
    )
    parser.add_argument(
        "--max-personas",
        type=int,
        default=3,
        help="æœ€å¤§é¸å®šãƒšãƒ«ã‚½ãƒŠæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3)"
    )
    parser.add_argument(
        "--max-posts",
        type=int,
        default=20,
        help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§æŠ•ç¨¿æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="persona_report.md",
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: persona_report.md)"
    )

    args = parser.parse_args()

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    pipeline = NemotronInstagramPipeline()
    result = pipeline.run(
        target_description=args.target,
        max_personas=args.max_personas,
        max_posts_per_keyword=args.max_posts
    )

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    if result["success"]:
        with open(args.output, "w", encoding="utf-8") as f:
            f.write(result["markdown_report"])

        print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {args.output}")
        print(f"ğŸ“Š çµ±åˆãƒšãƒ«ã‚½ãƒŠæ•°: {result['total_personas']}ä»¶")
        print(f"â­ å¹³å‡ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {result['avg_trust_score']:.1f}/100")
    else:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {result.get('error')}")
        sys.exit(1)
